import torch
from ultralytics import YOLO
from transformers import BlipProcessor, BlipForConditionalGeneration
from paddleocr import PaddleOCR
import json
from openai import OpenAI
from PIL import Image
import logging
import streamlit as st
import json
import os
import re
from openai import OpenAI
from datetime import datetime

# ==========================================
# å…¨å±€æ—¥å¿—ç³»ç»Ÿé…ç½®
# ==========================================
LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)

# æ¯å¤©ç”Ÿæˆä¸€ä¸ªç‹¬ç«‹çš„æ—¥å¿—æ–‡ä»¶
log_filename = datetime.now().strftime("agent_%Y%m%d.log")
log_filepath = os.path.join(LOG_DIR, log_filename)

# 1. è·å–æˆ‘ä»¬ä¸“å±çš„ç‹¬ç«‹ loggerï¼Œä¸ä½¿ç”¨å…¨å±€ basicConfig
logger = logging.getLogger("VisionAgent")
logger.setLevel(logging.INFO)

# 2. æ ¸å¿ƒï¼šåˆ¤æ–­æ˜¯å¦å·²ç»æ·»åŠ è¿‡ï¼ˆé˜²æ­¢ Streamlit åˆ·æ–°å¯¼è‡´é‡å¤æ‰“å°ï¼‰
if not logger.handlers:
    # é…ç½®æ–‡ä»¶å†™å…¥é€šé“
    file_handler = logging.FileHandler(log_filepath, encoding='utf-8')
    file_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))
    logger.addHandler(file_handler)
    
    # é…ç½®ç»ˆç«¯æ‰“å°é€šé“
    stream_handler = logging.StreamHandler()
    stream_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s'))
    logger.addHandler(stream_handler)
    
    # åˆ‡æ–­ä¸å…¨å±€æ—¥å¿—çš„è”ç³»ï¼Œé˜²æ­¢è¢«å…¶ä»–åº“å¹²æ‰°æˆ–æ‰“å°åŒä»½
    logger.propagate = False

# é™éŸ³ PaddleOCR çš„åºŸè¯
logging.getLogger("ppocr").setLevel(logging.ERROR)
# ==========================================
# åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯
# ==========================================

def load_api_key():
    with open('config.json', 'r', encoding='utf-8') as f:
        return json.load(f).get('deepseek_api_key')
client = OpenAI(api_key=load_api_key(), base_url="https://api.deepseek.com/v1")

# ==========================================
# å°†æ¨¡å‹æ°¸ä¹…ç¼“å­˜åˆ°æ˜¾å­˜ä¸­
# ==========================================
@st.cache_resource
def load_ai_models():
    """åªæœ‰åœ¨ç¬¬ä¸€æ¬¡æ‰“å¼€ç½‘é¡µæ—¶æ‰ä¼šæ‰§è¡Œï¼Œåç»­æ‰€æœ‰æ“ä½œç›´æ¥ä»å†…å­˜è¯»å–"""
    print("[ç³»ç»Ÿæ—¥å¿—] æ­£åœ¨å¯åŠ¨ AI å¼•æ“å¹¶è£…è½½æ¨¡å‹ (ä»…æ‰§è¡Œä¸€æ¬¡)...")
    
    # å±è”½ PaddleOCR çƒ¦äººçš„çº¢è‰²è°ƒè¯•æ—¥å¿—
    logging.getLogger("ppocr").setLevel(logging.ERROR) 
    
    ocr = PaddleOCR(lang="ch")
    yolo = YOLO("yolov8n.pt")
    
    blip_p = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
    blip_m = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
    
    # å¦‚æœæœ‰ GPUï¼Œé¡ºä¾¿æŠŠ BLIP æå‰ç§»åŠ¨åˆ° GPU ä¸Šï¼Œé¿å…æ¯æ¬¡è¯†åˆ«æ—¶åå¤æ¬è¿
    if torch.cuda.is_available():
        blip_m.to("cuda")
        
    print("[ç³»ç»Ÿæ—¥å¿—] æ‰€æœ‰ AI æ¨¡å‹å·²é”å®šåœ¨å†…å­˜ä¸­ï¼")
    return ocr, yolo, blip_p, blip_m

with st.spinner("æ­£åœ¨å°†è§†è§‰æ¨¡å‹è£…è½½åˆ°æ˜¾å­˜ä¸­ï¼Œè¯·ç¨å€™ï¼ˆä»…å¯åŠ¨æ—¶åŠ è½½ä¸€æ¬¡ï¼‰..."):
    ocr_engine, yolo_engine, blip_processor, blip_model = load_ai_models()

def real_run_ocr(image_path):
    print(f"\n[ç³»ç»Ÿæ—¥å¿—] æ­£åœ¨è°ƒç”¨çœŸå®çš„ PaddleOCR æ‰«æå›¾ç‰‡: {image_path}...")
    try:
        result = ocr_engine.ocr(image_path)
        if not result or not result[0]:
            return f"æœªèƒ½åœ¨å›¾ç‰‡ '{image_path}' ä¸­è¯†åˆ«åˆ°ä»»ä½•æ–‡å­—ã€‚"

        extracted_texts = [line[1][0] for line in result[0]]
        final_text = "\n".join(extracted_texts)
        print(f"[ç³»ç»Ÿæ—¥å¿—] OCR æ‰«æå®Œæˆã€‚")
        return final_text
    except Exception as e:
        return f"OCR ä»£ç æ‰§è¡Œå‡ºé”™ï¼ŒåŸå› ï¼š{str(e)}"

def real_run_yolo(image_path):
    print(f"\n[ç³»ç»Ÿæ—¥å¿—] æ­£åœ¨è°ƒç”¨ YOLO æ£€æµ‹å›¾ç‰‡: {image_path}...")
    try:
        results = yolo_engine(image_path, verbose=False)
        detected_objects = []
        for result in results:
            boxes = result.boxes
            for box in boxes:
                class_id = int(box.cls[0])
                class_name = yolo_engine.names[class_id]
                detected_objects.append(class_name)
        
        if not detected_objects:
            return "æœªåœ¨å›¾ç‰‡ä¸­æ£€æµ‹åˆ°ä»»ä½•å¸¸è§ç‰©ä½“ã€‚"
            
        from collections import Counter
        object_counts = Counter(detected_objects)
        result_json = json.dumps(dict(object_counts), ensure_ascii=False)
        print(f"[ç³»ç»Ÿæ—¥å¿—] YOLO æ£€æµ‹å®Œæˆ: {result_json}")
        return f"å›¾ç‰‡ä¸­åŒ…å«ä»¥ä¸‹ç‰©ä½“åŠæ•°é‡ï¼ˆè‹±æ–‡æ ‡ç­¾ï¼‰ï¼š{result_json}"
    except Exception as e:
        return f"YOLO æ£€æµ‹å¤±è´¥ï¼ŒåŸå› ï¼š{str(e)}"
    
def real_run_blip(image_path):
    print(f"\n[ç³»ç»Ÿæ—¥å¿—] æ­£åœ¨è°ƒç”¨ BLIP æè¿°å›¾ç‰‡: {image_path}...")
    try:
        raw_image = Image.open(image_path).convert('RGB')
        inputs = blip_processor(raw_image, return_tensors="pt")
        # å°†å¼ é‡ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡ï¼ˆå¦‚æœç”¨çš„æ˜¯ GPUï¼‰
        device = "cuda" if torch.cuda.is_available() else "cpu"
        blip_model.to(device)
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
        out = blip_model.generate(**inputs, max_new_tokens=50)
        caption = blip_processor.decode(out[0], skip_special_tokens=True)
        print(f"[ç³»ç»Ÿæ—¥å¿—] BLIP æè¿°å®Œæˆ: {caption}")
        return f"å›¾ç‰‡çš„æ•´ä½“åœºæ™¯æè¿°ä¸ºï¼ˆè‹±æ–‡ï¼‰ï¼š{caption}"
    except Exception as e:
        return f"BLIP æè¿°å¤±è´¥ï¼ŒåŸå› ï¼š{str(e)}"  
    
tools = [
    {
        "type": "function",
        "function": {
            "name": "run_ocr",
            "description": "å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰å·¥å…·ã€‚å½“éœ€è¦æå–å›¾ç‰‡ä¸­çš„æ–‡å­—æ—¶è°ƒç”¨ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "image_path": {
                        "type": "string", 
                        "description": "å›¾ç‰‡è·¯å¾„"
                    },
                    "lang": {
                        "type": "string", 
                        "description": "æŒ‡å®šè¦è¯†åˆ«çš„è¯­è¨€ï¼Œé»˜è®¤ä¸º 'ch'ï¼ˆä¸­è‹±æ–‡æ··åˆï¼‰ï¼Œå¦‚æœå…¨æ˜¯è‹±æ–‡è¯·ä¼ å…¥ 'en'"
                    }
                },
                "required": ["image_path"] # lang æ˜¯å¯é€‰å‚æ•°ï¼Œå¤§æ¨¡å‹å¯ä»¥è‡ªå·±å†³å®šä¼ ä¸ä¼ 
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "run_yolo",
            "description": "ç›®æ ‡æ£€æµ‹å·¥å…·ã€‚ç”¨äºç»Ÿè®¡å›¾ç‰‡é‡Œçš„ç‰©ä½“å’Œæ•°é‡ã€‚",
            "parameters": {
                "type": "object",
                "properties": {
                    "image_path": {"type": "string", "description": "å›¾ç‰‡è·¯å¾„"},
                    "target": {"type": "string", "description": "å¦‚æœç”¨æˆ·åªæƒ³æ‰¾ç‰¹å®šç‰©ä½“ï¼ˆå¦‚'äºº'ï¼‰ï¼Œåœ¨è¿™é‡Œä¼ å…¥è‹±æ–‡æ ‡ç­¾ï¼ˆå¦‚'person'ï¼‰ã€‚å¦‚æœè¦æ‰¾æ‰€æœ‰ç‰©ä½“ï¼Œè¯·å¿½ç•¥æ­¤å‚æ•°ã€‚"}
                },
                "required": ["image_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "run_blip",
            "description": "å›¾åƒåœºæ™¯æè¿°å·¥å…·ã€‚ç”¨äºäº†è§£å›¾ç‰‡æ•´ä½“ç”»äº†ä»€ä¹ˆã€‚",
            "parameters": {
                "type": "object",
                "properties": {"image_path": {"type": "string", "description": "å›¾ç‰‡è·¯å¾„"}},
                "required": ["image_path"]
            }
        }
    }
]

# ==========================================
# å¤šä¼šè¯æ–‡ä»¶ç®¡ç†ç³»ç»Ÿ
# ==========================================
UPLOAD_DIR = "uploads"
SESSION_DIR = "sessions"
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(SESSION_DIR, exist_ok=True)

def start_new_chat():
    """åˆå§‹åŒ–ä¸€ä¸ªå…¨æ–°çš„ä¼šè¯"""
    st.session_state.session_id = datetime.now().strftime("%Y%m%d_%H%M%S") # ç”¨æ—¶é—´æˆ³åšå”¯ä¸€ID
    st.session_state.timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.messages = []
    st.session_state.current_image_path = None

def save_session():
    """æŠŠå½“å‰ä¼šè¯è¿åŒå›¾ç‰‡è·¯å¾„ï¼Œä¿å­˜ä¸ºç‹¬ç«‹çš„ JSON æ–‡ä»¶"""
    if not st.session_state.messages: 
        return # ç©ºå¯¹è¯ä¸ä¿å­˜
    
    session_data = {
        "session_id": st.session_state.session_id,
        "timestamp": st.session_state.timestamp,
        "image_path": st.session_state.current_image_path,
        # è¿‡æ»¤æ‰åº•å±‚ç¹æ‚çš„ tool è°ƒç”¨è®°å½•ï¼Œåªä¿å­˜ä½ å’Œå¤§æ¨¡å‹çš„å¯¹è¯
        "messages": [m for m in st.session_state.messages if m.get("role") in ["user", "assistant"] and not m.get("tool_calls")],
        "raw_trace": st.session_state.messages
    }
    filepath = os.path.join(SESSION_DIR, f"{st.session_state.session_id}.json")
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(session_data, f, ensure_ascii=False, indent=2)

def get_all_sessions():
    """è¯»å–æ‰€æœ‰å†å²ä¼šè¯"""
    files = [f for f in os.listdir(SESSION_DIR) if f.endswith('.json')]
    sessions = []
    for file in files:
        with open(os.path.join(SESSION_DIR, file), "r", encoding="utf-8") as f:
            try:
                sessions.append(json.load(f))
            except:
                pass
    # æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨æœ€ä¸Šé¢ï¼‰
    sessions.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
    return sessions

def load_chat(session_data):
    """åŠ è½½é€‰ä¸­çš„å†å²ä¼šè¯"""
    st.session_state.session_id = session_data["session_id"]
    st.session_state.timestamp = session_data.get("timestamp", "")
    st.session_state.messages = session_data.get("messages", [])
    st.session_state.current_image_path = session_data.get("image_path")

# ==========================================
# ç½‘é¡µå‰ç«¯ UI ä¸ æ ¸å¿ƒé€»è¾‘
# ==========================================

st.set_page_config(page_title="Vision Agent", layout="wide")
st.title("llm-vision-agent")

# ç³»ç»Ÿåˆå§‹åŒ–ï¼šå¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ‰“å¼€ï¼Œå»ºç«‹æ–°ä¼šè¯
if "session_id" not in st.session_state:
    start_new_chat()

# --- ä¾§è¾¹æ ï¼šå†å²è®°å½•ä¸å›¾ç‰‡å·¥ä½œåŒº ---
with st.sidebar:
    # 1. é‡ç½®/æ–°å»ºå¯¹è¯æŒ‰é’®
    if st.button("+ æ–°å»ºå¯¹è¯ (é‡ç½®)", use_container_width=True, type="primary"):
        start_new_chat()
        st.rerun() # å¼ºåˆ¶åˆ·æ–°é¡µé¢
        
    st.divider()
    
    # 2. å›¾ç‰‡æ‹–æ‹½åŒº
    st.header("å›¾ç‰‡å·¥ä½œåŒº")
    # å·§å¦™çš„é­”æ³•ï¼šç»™ uploader åŠ ä¸Š session_id ä½œä¸º keyï¼Œè¿™æ ·æ–°å»ºå¯¹è¯æ—¶ä¸Šä¼ æ¡†ä¼šè‡ªåŠ¨æ¸…ç©ºï¼
    uploaded_file = st.file_uploader("æŠŠå›¾ç‰‡æ‹–åˆ°è¿™é‡Œ...", type=["png", "jpg", "jpeg", "webp"], key=f"uploader_{st.session_state.session_id}")
    
    if uploaded_file:
        file_path = os.path.join(UPLOAD_DIR, uploaded_file.name)
        with open(file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        st.session_state.current_image_path = file_path
        save_session() # ä¸Šä¼ å›¾ç‰‡ä¹Ÿè§¦å‘ä¸€æ¬¡ä¿å­˜
    
    # å±•ç¤ºå½“å‰ä¼šè¯ç»‘å®šçš„å›¾ç‰‡
    if st.session_state.current_image_path and os.path.exists(st.session_state.current_image_path):
        st.image(st.session_state.current_image_path, caption="å½“å‰å…³è”å›¾ç‰‡", use_container_width=True)
    
    st.divider()
    
    # 3. å†å²ä¼šè¯æ¼«æ¸¸åŒº
    st.header("å†å²ä¼šè¯")
    all_sessions = get_all_sessions()
    
    for sess in all_sessions:
        # æå–ç¬¬ä¸€å¥è¯ä½œä¸ºæ ‡é¢˜ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ˜¾ç¤ºâ€œæ–°å¯¹è¯â€
        msgs = sess.get("messages", [])
        time_str = sess.get("timestamp", "")[5:16] # æå– æœˆ-æ—¥ æ—¶:åˆ†
        if msgs:
            # æˆªå–ç”¨æˆ·è¯´çš„ç¬¬ä¸€å¥è¯ä½œä¸ºæŒ‰é’®åå­—
            first_msg = msgs[0]["content"].replace("\n", " ")[:12]
            btn_label = f"{time_str} | {first_msg}..."
        else:
            btn_label = f"âœ¨ {time_str} | ç©ºç™½å¯¹è¯"
            
        # æ¸²æŸ“å†å²è®°å½•æŒ‰é’®ï¼Œå¦‚æœæ˜¯å½“å‰é€‰ä¸­çš„ï¼Œé«˜äº®æ˜¾ç¤º
        is_current = (sess["session_id"] == st.session_state.session_id)
        if st.button(btn_label, key=f"btn_{sess['session_id']}", disabled=is_current, use_container_width=True):
            load_chat(sess)
            st.rerun()

# --- ä¸»èŠå¤©åŒºåŸŸå±•ç¤ºå†å²è®°å½• ---
for msg in st.session_state.messages:
    if msg["role"] in ["user", "assistant"]:
        with st.chat_message(msg["role"]):
            # æŠŠç³»ç»Ÿå¡å°æŠ„çš„å°¾å·´å»æ‰å†å±•ç¤ºï¼Œä¿æŒç•Œé¢æ•´æ´
            display_text = re.sub(r'\[ç³»ç»Ÿæç¤ºï¼šç”¨æˆ·å½“å‰èšç„¦çš„å›¾ç‰‡è·¯å¾„æ˜¯.*?\]', '', msg["content"]).strip()
            st.markdown(display_text)

# --- æ¥æ”¶ç”¨æˆ·è¾“å…¥ ---
user_input = st.chat_input("å‘ä¸€å¼ å›¾ç‰‡åˆ°å·¦ä¾§ï¼Œæˆ–é—®æˆ‘ä»»ä½•é—®é¢˜...")

if user_input:
    # 1. ç½‘é¡µä¸Šå±•ç¤ºç”¨æˆ·çš„è¾“å…¥
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # 2. åå°å¡å°æŠ„
    if st.session_state.current_image_path:
        prompt_for_llm = f"{user_input}\n\n[ç³»ç»Ÿæç¤ºï¼šç”¨æˆ·å½“å‰èšç„¦çš„å›¾ç‰‡è·¯å¾„æ˜¯ '{st.session_state.current_image_path}'ï¼Œè¯·ä½¿ç”¨æ­¤è·¯å¾„è°ƒç”¨è§†è§‰å·¥å…·]"
    else:
        prompt_for_llm = user_input
        
    st.session_state.messages.append({"role": "user", "content": prompt_for_llm})
    save_session() # æ¯è¯´ä¸€å¥è¯å°±ä¿å­˜ä¸€æ¬¡
    
    # 3. å¬å”¤å¤§æ¨¡å‹
    with st.chat_message("assistant"):
        status_box = st.status("Agent æ­£åœ¨æ€è€ƒå¹¶è°ƒç”¨è§†è§‰å·¥å…·...", expanded=True)
        
        MAX_ROUNDS = 3
        current_round = 1
        current_messages = st.session_state.messages.copy() 
        
        while current_round <= MAX_ROUNDS:
            status_box.write(f"ç¬¬ {current_round} è½®æ€è€ƒä¸­...")
            logger.info(f"\n{'='*40}\n[Session: {st.session_state.session_id} | Round: {current_round}]\nğŸš€ å‘é€ç»™å¤§æ¨¡å‹çš„ Messages:\n{json.dumps(current_messages, ensure_ascii=False, indent=2)}\n{'='*40}")
            if current_round == MAX_ROUNDS:
                current_messages.append({
                    "role": "user",
                    "content": "ã€ç³»ç»Ÿå¼ºåˆ¶æŒ‡ä»¤ã€‘ï¼šç”±äºèµ„æºé™åˆ¶ï¼Œæ— æ³•å†è°ƒç”¨ä»»ä½•å·¥å…·ã€‚è¯·ç«‹åˆ»åŸºäºå·²æœ‰çš„å·¥å…·æ£€æµ‹ç»“æœå›ç­”ï¼Œç»å¯¹ä¸è¦è¾“å‡ºå·¥å…·è°ƒç”¨ä»£ç ï¼"
                })
                response = client.chat.completions.create(model="deepseek-chat", messages=current_messages)
            else:
                response = client.chat.completions.create(model="deepseek-chat", messages=current_messages, tools=tools, tool_choice="auto")
            
            ai_message = response.choices[0].message
            logger.info(f"å¤§æ¨¡å‹åŸå§‹å›å¤:\n{ai_message.model_dump_json(indent=2)}")
            ai_message_dict = {"role": ai_message.role, "content": ai_message.content}
            
            if ai_message.tool_calls:
                ai_message_dict["tool_calls"] = [{"id": t.id, "type": t.type, "function": {"name": t.function.name, "arguments": t.function.arguments}} for t in ai_message.tool_calls]
            
            if current_round < MAX_ROUNDS and ai_message.tool_calls:
                current_messages.append(ai_message_dict)
                for tool_call in ai_message.tool_calls:
                    func_name = tool_call.function.name
                    func_args = json.loads(tool_call.function.arguments)
                    status_box.write(f"å†³å®šè°ƒç”¨å·¥å…·ï¼š{func_name}")
                    
                    if func_name == "run_ocr":
                        tool_result = real_run_ocr(func_args.get("image_path")) 
                    elif func_name == "run_yolo":
                        tool_result = real_run_yolo(func_args.get("image_path"))
                    elif func_name == "run_blip":
                        tool_result = real_run_blip(func_args.get("image_path"))
                    else:
                        tool_result = "æœªçŸ¥çš„å·¥å…·åç§°"
                    logger.info(f"å·¥å…· [{func_name}] æ‰§è¡Œç»“æœ:\n{tool_result}")
                    status_box.write(f"{func_name} æ‰§è¡Œå®Œæ¯•ã€‚")
                    current_messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "name": func_name,
                        "content": tool_result
                    })
                current_round += 1
            else:
                final_text = ai_message.content or ""
                final_text = re.sub(r'<ï½œDSMLï½œ.*?(?:</ï½œDSMLï½œfunction_calls>|$)', '', final_text, flags=re.DOTALL).strip()
                logger.info(f"æœ€ç»ˆäº¤ä»˜ç»™ç”¨æˆ·çš„å›å¤:\n{final_text}")
                status_box.update(label="æ€è€ƒå®Œæ¯•ï¼", state="complete", expanded=False)
                st.markdown(final_text)
                
                st.session_state.messages.append({"role": "assistant", "content": final_text})
                save_session() # æ‹¿åˆ°æœ€ç»ˆå›ç­”åå†æ¬¡ä¿å­˜
                break